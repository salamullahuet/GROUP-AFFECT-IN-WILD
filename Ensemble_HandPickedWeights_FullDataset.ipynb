{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_HandPickedWeights_FullDataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W1bVRTVvhsm"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PODdBi6FvnZb"
      },
      "source": [
        "label_to_name = { 0 : 'Negative',\r\n",
        "                  1 : 'Neutral',\r\n",
        "                  2 : 'Positive'}\r\n",
        "\r\n",
        "path_eval_output_data = '/content/drive/MyDrive/fourteen_fulltrained_models_output_data.npz'\r\n",
        "path_test_output_data = '/content/drive/MyDrive/test_data_fourteen_fulltrained_models_outputs.npz'\r\n",
        "submission_folder = '/content/Submission_8/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sh7DE0DyLXF"
      },
      "source": [
        "def softmax(x):\r\n",
        "    \"\"\"\r\n",
        "    Compute softmax values for each sets of scores in x.\r\n",
        "    \r\n",
        "    Rows are scores for each class. \r\n",
        "    Columns are predictions (samples).\r\n",
        "    \"\"\"\r\n",
        "    scoreMatExp = np.exp(np.asarray(x))\r\n",
        "    \r\n",
        "    result = np.zeros((scoreMatExp.shape[0], 3))\r\n",
        "    \r\n",
        "    result[:, 0] = scoreMatExp[:, 0] / scoreMatExp.sum(1)\r\n",
        "    result[:, 1] = scoreMatExp[:, 1] / scoreMatExp.sum(1)\r\n",
        "    result[:, 2] = scoreMatExp[:, 2] / scoreMatExp.sum(1)\r\n",
        "    \r\n",
        "    return result"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP0jOpz1yblI",
        "outputId": "568ffe51-0e6e-4a6d-a857-84867b146c09"
      },
      "source": [
        "\r\n",
        "data_eval = np.load(path_eval_output_data)\r\n",
        "model1_eval = data_eval['output_test_model1']\r\n",
        "model2_eval = data_eval['output_test_model2']\r\n",
        "model3_eval = data_eval['output_test_model3']\r\n",
        "model4_eval = data_eval['output_test_model4']\r\n",
        "model5_eval = data_eval['output_test_model5']\r\n",
        "model6_eval = data_eval['output_test_model6']\r\n",
        "model7_eval = data_eval['output_test_model7']\r\n",
        "model8_eval = data_eval['output_test_model8']\r\n",
        "model9_eval = data_eval['output_test_model9']\r\n",
        "model10_eval = data_eval['output_test_model10']\r\n",
        "model11_eval = data_eval['output_test_model11']\r\n",
        "model12_eval = data_eval['output_test_model12']\r\n",
        "model13_eval = data_eval['output_test_model13']\r\n",
        "model14_eval = data_eval['output_test_model14']\r\n",
        "eval_label = data_eval['label_test']\r\n",
        "print('EVAL Dataset Loaded')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EVAL Dataset Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz0zW-j8zBz-",
        "outputId": "7186c927-77bc-473c-bf53-5ba1e5273e22"
      },
      "source": [
        "data_test = np.load(path_test_output_data)\r\n",
        "model1_test = data_test['output_test_model1']\r\n",
        "model2_test = data_test['output_test_model2']\r\n",
        "model3_test = data_test['output_test_model3']\r\n",
        "model4_test = data_test['output_test_model4']\r\n",
        "model5_test = data_test['output_test_model5']\r\n",
        "model6_test = data_test['output_test_model6']\r\n",
        "model7_test = data_test['output_test_model7']\r\n",
        "model8_test = data_test['output_test_model8']\r\n",
        "model9_test = data_test['output_test_model9']\r\n",
        "model10_test = data_test['output_test_model10']\r\n",
        "model11_test = data_test['output_test_model11']\r\n",
        "model12_test = data_test['output_test_model12']\r\n",
        "model13_test = data_test['output_test_model13']\r\n",
        "model14_test = data_test['output_test_model14']\r\n",
        "test_filenames = data_test['filename_test']\r\n",
        "print('TEST Dataset Loaded')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST Dataset Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_2jTOaAzKEi"
      },
      "source": [
        "model1_eval = softmax(model1_eval)\r\n",
        "model2_eval = softmax(model2_eval)\r\n",
        "model3_eval = softmax(model3_eval)\r\n",
        "model4_eval = softmax(model4_eval)\r\n",
        "model5_eval = softmax(model5_eval)\r\n",
        "model6_eval = softmax(model6_eval)\r\n",
        "model7_eval = softmax(model7_eval)\r\n",
        "model8_eval = softmax(model8_eval)\r\n",
        "model9_eval = softmax(model9_eval)\r\n",
        "model10_eval = softmax(model10_eval)\r\n",
        "model11_eval = softmax(model11_eval)\r\n",
        "model12_eval = softmax(model12_eval)\r\n",
        "model13_eval = softmax(model13_eval)\r\n",
        "model14_eval = softmax(model14_eval)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK4foIHUzS47"
      },
      "source": [
        "m1 = 1\r\n",
        "m2 = 1\r\n",
        "m3 = 1\r\n",
        "m4 = 1\r\n",
        "m5 = 1\r\n",
        "m6 = 1\r\n",
        "m7 = 1\r\n",
        "m8 = 1\r\n",
        "m9 = 1\r\n",
        "m10 = 1\r\n",
        "m11 = 1\r\n",
        "m12 = 1\r\n",
        "m13 = 1\r\n",
        "m14 = 1\r\n",
        "\r\n",
        "output_eval = (m1 * model1_eval) + (m2 * model2_eval) + (m3 * model3_eval) + (m4 * model4_eval) +\\\r\n",
        "(m5*model5_eval) + (m6*model6_eval) + (m7*model7_eval) + (m8*model8_eval) + (m9*model9_eval) +\\\r\n",
        "(m10*model10_eval) + (m11*model11_eval) + (m12*model12_eval) + (m13*model13_eval) + (m14*model14_eval)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaLVlLAqzbiQ"
      },
      "source": [
        "pred_eval = np.argmax(output_eval, axis = 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQievs5Wzis0"
      },
      "source": [
        "correct_eval = np.sum(pred_eval == eval_label)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hHzODCsznZM",
        "outputId": "88546dd5-4fa0-4634-f726-4574e1940c12"
      },
      "source": [
        "eval_accuracy = correct_eval / output_eval.shape[0]\r\n",
        "print(eval_accuracy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Upqt09ztvR"
      },
      "source": [
        "model1_test = softmax(model1_test)\r\n",
        "model2_test = softmax(model2_test)\r\n",
        "model3_test = softmax(model3_test)\r\n",
        "model4_test = softmax(model4_test)\r\n",
        "model5_test = softmax(model5_test)\r\n",
        "model6_test = softmax(model6_test)\r\n",
        "model7_test = softmax(model7_test)\r\n",
        "model8_test = softmax(model8_test)\r\n",
        "model9_test = softmax(model9_test)\r\n",
        "model10_test = softmax(model10_test)\r\n",
        "model11_test = softmax(model11_test)\r\n",
        "model12_test = softmax(model12_test)\r\n",
        "model13_test = softmax(model13_test)\r\n",
        "model14_test = softmax(model14_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mefJQz1Rzy2X"
      },
      "source": [
        "m1 = 1\r\n",
        "m2 = 1\r\n",
        "m3 = 1\r\n",
        "m4 = 1\r\n",
        "m5 = 1\r\n",
        "m6 = 1\r\n",
        "m7 = 1\r\n",
        "m8 = 1\r\n",
        "m9 = 1\r\n",
        "m10 = 1\r\n",
        "m11 = 1\r\n",
        "m12 = 1\r\n",
        "m13 = 1\r\n",
        "m14 = 1\r\n",
        "\r\n",
        "output_test = (m1 * model1_test) + (m2 * model2_test) + (m3 * model3_test) + (m4 * model4_test) +\\\r\n",
        "(m5*model5_test) + (m6*model6_test) + (m7*model7_test) + (m8*model8_test) + (m9*model9_test) +\\\r\n",
        "(m10*model10_test) + (m11*model11_test) + (m12*model12_test) + (m13*model13_test) + (m14*model14_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxk7heez7Vb"
      },
      "source": [
        "predictions_test = np.argmax(output_test, axis = 1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmMB-BSn0FRQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}