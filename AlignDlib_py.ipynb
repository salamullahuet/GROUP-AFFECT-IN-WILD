{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlignDlib.py.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDxPoy6Z8twB",
        "outputId": "8e32db4e-a278-4427-f9c5-c9dd66564be8"
      },
      "source": [
        "from google.colab import drive\r\n",
        "from google.colab import files\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M44ySy-UqwiS"
      },
      "source": [
        "# #### 3.4 Dlib Align Class\r\n",
        "# Copyright 2015-2016 Carnegie Mellon University\r\n",
        "#\r\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        "# you may not use this file except in compliance with the License.\r\n",
        "# You may obtain a copy of the License at\r\n",
        "#\r\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\r\n",
        "#\r\n",
        "# Unless required by applicable law or agreed to in writing, software\r\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        "# See the License for the specific language governing permissions and\r\n",
        "# limitations under the License.\r\n",
        "\r\n",
        "\"\"\"Module for dlib-based alignment.\"\"\"\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import dlib\r\n",
        "import cv2\r\n",
        "\r\n",
        "TEMPLATE = np.float32([\r\n",
        "    (0.0792396913815, 0.339223741112), (0.0829219487236, 0.456955367943),\r\n",
        "    (0.0967927109165, 0.575648016728), (0.122141515615, 0.691921601066),\r\n",
        "    (0.168687863544, 0.800341263616), (0.239789390707, 0.895732504778),\r\n",
        "    (0.325662452515, 0.977068762493), (0.422318282013, 1.04329000149),\r\n",
        "    (0.531777802068, 1.06080371126), (0.641296298053, 1.03981924107),\r\n",
        "    (0.738105872266, 0.972268833998), (0.824444363295, 0.889624082279),\r\n",
        "    (0.894792677532, 0.792494155836), (0.939395486253, 0.681546643421),\r\n",
        "    (0.96111933829, 0.562238253072), (0.970579841181, 0.441758925744),\r\n",
        "    (0.971193274221, 0.322118743967), (0.163846223133, 0.249151738053),\r\n",
        "    (0.21780354657, 0.204255863861), (0.291299351124, 0.192367318323),\r\n",
        "    (0.367460241458, 0.203582210627), (0.4392945113, 0.233135599851),\r\n",
        "    (0.586445962425, 0.228141644834), (0.660152671635, 0.195923841854),\r\n",
        "    (0.737466449096, 0.182360984545), (0.813236546239, 0.192828009114),\r\n",
        "    (0.8707571886, 0.235293377042), (0.51534533827, 0.31863546193),\r\n",
        "    (0.516221448289, 0.396200446263), (0.517118861835, 0.473797687758),\r\n",
        "    (0.51816430343, 0.553157797772), (0.433701156035, 0.604054457668),\r\n",
        "    (0.475501237769, 0.62076344024), (0.520712933176, 0.634268222208),\r\n",
        "    (0.565874114041, 0.618796581487), (0.607054002672, 0.60157671656),\r\n",
        "    (0.252418718401, 0.331052263829), (0.298663015648, 0.302646354002),\r\n",
        "    (0.355749724218, 0.303020650651), (0.403718978315, 0.33867711083),\r\n",
        "    (0.352507175597, 0.349987615384), (0.296791759886, 0.350478978225),\r\n",
        "    (0.631326076346, 0.334136672344), (0.679073381078, 0.29645404267),\r\n",
        "    (0.73597236153, 0.294721285802), (0.782865376271, 0.321305281656),\r\n",
        "    (0.740312274764, 0.341849376713), (0.68499850091, 0.343734332172),\r\n",
        "    (0.353167761422, 0.746189164237), (0.414587777921, 0.719053835073),\r\n",
        "    (0.477677654595, 0.706835892494), (0.522732900812, 0.717092275768),\r\n",
        "    (0.569832064287, 0.705414478982), (0.635195811927, 0.71565572516),\r\n",
        "    (0.69951672331, 0.739419187253), (0.639447159575, 0.805236879972),\r\n",
        "    (0.576410514055, 0.835436670169), (0.525398405766, 0.841706377792),\r\n",
        "    (0.47641545769, 0.837505914975), (0.41379548902, 0.810045601727),\r\n",
        "    (0.380084785646, 0.749979603086), (0.477955996282, 0.74513234612),\r\n",
        "    (0.523389793327, 0.748924302636), (0.571057789237, 0.74332894691),\r\n",
        "    (0.672409137852, 0.744177032192), (0.572539621444, 0.776609286626),\r\n",
        "    (0.5240106503, 0.783370783245), (0.477561227414, 0.778476346951)])\r\n",
        "\r\n",
        "TPL_MIN, TPL_MAX = np.min(TEMPLATE, axis=0), np.max(TEMPLATE, axis=0)\r\n",
        "MINMAX_TEMPLATE = (TEMPLATE - TPL_MIN) / (TPL_MAX - TPL_MIN)\r\n",
        "\r\n",
        "\r\n",
        "class AlignDlib:\r\n",
        "    \"\"\"\r\n",
        "    Use `dlib's landmark estimation <http://blog.dlib.net/2014/08/real-time-face-pose-estimation.html>`_ to align faces.\r\n",
        "    The alignment preprocess faces for input into a neural network.\r\n",
        "    Faces are resized to the same size (such as 96x96) and transformed\r\n",
        "    to make landmarks (such as the eyes and nose) appear at the same\r\n",
        "    location on every image.\r\n",
        "    Normalized landmarks:\r\n",
        "    .. image:: ../images/dlib-landmark-mean.png\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #: Landmark indices.\r\n",
        "    INNER_EYES_AND_BOTTOM_LIP = [39, 42, 57]\r\n",
        "    OUTER_EYES_AND_NOSE = [36, 45, 33]\r\n",
        "\r\n",
        "    def __init__(self, facePredictor):\r\n",
        "        \"\"\"\r\n",
        "        Instantiate an 'AlignDlib' object.\r\n",
        "        :param facePredictor: The path to dlib's\r\n",
        "        :type facePredictor: str\r\n",
        "        \"\"\"\r\n",
        "        assert facePredictor is not None\r\n",
        "\r\n",
        "        self.detector = dlib.get_frontal_face_detector()\r\n",
        "        self.predictor = dlib.shape_predictor(facePredictor)\r\n",
        "\r\n",
        "    def getAllFaceBoundingBoxes(self, rgbImg):\r\n",
        "        \"\"\"\r\n",
        "        Find all face bounding boxes in an image.\r\n",
        "        :param rgbImg: RGB image to process. Shape: (height, width, 3)\r\n",
        "        :type rgbImg: numpy.ndarray\r\n",
        "        :return: All face bounding boxes in an image.\r\n",
        "        :rtype: dlib.rectangles\r\n",
        "        \"\"\"\r\n",
        "        assert rgbImg is not None\r\n",
        "\r\n",
        "        try:\r\n",
        "            return self.detector(rgbImg, 1)\r\n",
        "        except Exception as e:\r\n",
        "            print(\"Warning: {}\".format(e))\r\n",
        "            # In rare cases, exceptions are thrown.\r\n",
        "            return []\r\n",
        "\r\n",
        "    def getLargestFaceBoundingBox(self, rgbImg, skipMulti=False):\r\n",
        "        \"\"\"\r\n",
        "        Find the largest face bounding box in an image.\r\n",
        "        :param rgbImg: RGB image to process. Shape: (height, width, 3)\r\n",
        "        :type rgbImg: numpy.ndarray\r\n",
        "        :param skipMulti: Skip image if more than one face detected.\r\n",
        "        :type skipMulti: bool\r\n",
        "        :return: The largest face bounding box in an image, or None.\r\n",
        "        :rtype: dlib.rectangle\r\n",
        "        \"\"\"\r\n",
        "        assert rgbImg is not None\r\n",
        "\r\n",
        "        faces = self.getAllFaceBoundingBoxes(rgbImg)\r\n",
        "        if (not skipMulti and len(faces) > 0) or len(faces) == 1:\r\n",
        "            return max(faces, key=lambda rect: rect.width() * rect.height())\r\n",
        "        else:\r\n",
        "            return None\r\n",
        "\r\n",
        "    def findLandmarks(self, rgbImg, bb):\r\n",
        "        \"\"\"\r\n",
        "        Find the landmarks of a face.\r\n",
        "        :param rgbImg: RGB image to process. Shape: (height, width, 3)\r\n",
        "        :type rgbImg: numpy.ndarray\r\n",
        "        :param bb: Bounding box around the face to find landmarks for.\r\n",
        "        :type bb: dlib.rectangle\r\n",
        "        :return: Detected landmark locations.\r\n",
        "        :rtype: list of (x,y) tuples\r\n",
        "        \"\"\"\r\n",
        "        assert rgbImg is not None\r\n",
        "        assert bb is not None\r\n",
        "\r\n",
        "        points = self.predictor(rgbImg, bb)\r\n",
        "        return list(map(lambda p: (p.x, p.y), points.parts()))\r\n",
        "\r\n",
        "    def align(self, imgDim, rgbImg, bb=None,\r\n",
        "              landmarks=None, landmarkIndices=INNER_EYES_AND_BOTTOM_LIP,\r\n",
        "              skipMulti=False):\r\n",
        "        r\"\"\"align(imgDim, rgbImg, bb=None, landmarks=None, landmarkIndices=INNER_EYES_AND_BOTTOM_LIP)\r\n",
        "        Transform and align a face in an image.\r\n",
        "        :param imgDim: The edge length in pixels of the square the image is resized to.\r\n",
        "        :type imgDim: int\r\n",
        "        :param rgbImg: RGB image to process. Shape: (height, width, 3)\r\n",
        "        :type rgbImg: numpy.ndarray\r\n",
        "        :param bb: Bounding box around the face to align. \\\r\n",
        "                   Defaults to the largest face.\r\n",
        "        :type bb: dlib.rectangle\r\n",
        "        :param landmarks: Detected landmark locations. \\\r\n",
        "                          Landmarks found on `bb` if not provided.\r\n",
        "        :type landmarks: list of (x,y) tuples\r\n",
        "        :param landmarkIndices: The indices to transform to.\r\n",
        "        :type landmarkIndices: list of ints\r\n",
        "        :param skipMulti: Skip image if more than one face detected.\r\n",
        "        :type skipMulti: bool\r\n",
        "        :return: The aligned RGB image. Shape: (imgDim, imgDim, 3)\r\n",
        "        :rtype: numpy.ndarray\r\n",
        "        \"\"\"\r\n",
        "        assert imgDim is not None\r\n",
        "        assert rgbImg is not None\r\n",
        "        assert landmarkIndices is not None\r\n",
        "\r\n",
        "        if bb is None:\r\n",
        "            bb = self.getLargestFaceBoundingBox(rgbImg, skipMulti)\r\n",
        "            if bb is None:\r\n",
        "                return\r\n",
        "\r\n",
        "        if landmarks is None:\r\n",
        "            landmarks = self.findLandmarks(rgbImg, bb)\r\n",
        "\r\n",
        "        npLandmarks = np.float32(landmarks)\r\n",
        "        npLandmarkIndices = np.array(landmarkIndices)\r\n",
        "\r\n",
        "        H = cv2.getAffineTransform(npLandmarks[npLandmarkIndices],\r\n",
        "                                   imgDim * MINMAX_TEMPLATE[npLandmarkIndices])\r\n",
        "        thumbnail = cv2.warpAffine(rgbImg, H, (imgDim, imgDim))\r\n",
        "\r\n",
        "        return thumbnail"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tWXexukuUqF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}